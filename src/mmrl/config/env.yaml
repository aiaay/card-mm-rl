kind: "single" # or "two"

# Episode (lengthened for more actions per episode)
episode_length: 20
W0: 500.0
# Softer stop-out to reduce premature termination during exploration
stop_out: 0.1 # Fraction of W0

# Market Dynamics
sigma_q: 0.5
spread:
  s0: 0.8
  beta: 0.25
  min: 1.0
  max: 3.0

liquidity:
  k: 10.0 # Depth scaling
  tau: 0.6 # Lognormal sigma
  min: 2.0
  max: 20.0
  cap: 10.0 # Display cap

# Gentler impact during training; can raise back up for eval
alpha: 0.15 # Impact slope

# Penalty for taking "Pass" action (0) to discourage passivity
pass_penalty: 0.05
# Max consecutive passes allowed before Pass (action 0) is masked out
max_consecutive_passes: 3

# Events
flags:
  enable_events: true
  # Disable impact during training to avoid discouraging actions;
  # turn back to true for more realistic eval.
  enable_impact: false

events:
  # Probabilities if last_event was none or not persistent
  freq:
    none: 0.6
    even_only: 0.1
    odd_only: 0.1
    ge10_only: 0.1
    le7_only: 0.1
    remap_value: 0.0 # Special case, handled manually if needed
  
  persistence: 0.7 # Prob to repeat last event

hints:
  count: 2 # Random 0..3 if not set, or fixed
